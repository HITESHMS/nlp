{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"nlp ex2.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyMnkq6ojNLrtaRG5rI6rJP5"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"AaHMUG0PYSNq"},"outputs":[],"source":["import nltk\n","nltk.download('all')\n","from nltk.corpus import stopwords"]},{"cell_type":"code","source":["import nltk\n","\n","word_data = \"It originated from the idea that there are readers who prefer learning new skills from the comforts of their drawing rooms\"\n","nltk_tokens = nltk.word_tokenize(word_data)\n","print (nltk_tokens)"],"metadata":{"id":"0fuPfYjNQG4b"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import nltk\n","sentence_data = \"Sun rises in the east. Sun sets in the west.\"\n","nltk_tokens = nltk.sent_tokenize(sentence_data)\n","print (nltk_tokens)"],"metadata":{"id":"qMDJeBXrRjPG"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["sentence_mix=' कौन है  class monitor ?'\n","print('after Filtration:'+ ''.join(list(filter(lambda x: ord(x) <123, sentence_mix))))"],"metadata":{"id":"KiD3_AiqRryY"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["\n","validated= [1,2,3,4,5]\n","removed_stopwords = ['one','two','three','four','five']\n","Validated = []\n","for w in removed_stopwords:\n"," validated.append(''.join([e for e in w if e.isalnum()]))\n","print(f'After script Validation: {validated}')"],"metadata":{"id":"H7xCdimBTUI_"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from nltk.corpus import stopwords\n","from nltk.tokenize import word_tokenize\n","\n","example_sent = \"\"\"This is a sample sentence,\n","\t\t\t\tshowing off the stop words filtration.\"\"\"\n","\n","stop_words = set(stopwords.words('english'))\n","\n","word_tokens = word_tokenize(example_sent)\n","\n","filtered_sentence = [w for w in word_tokens if not w.lower() in stop_words]\n","\n","filtered_sentence = []\n","\n","for w in word_tokens:\n","\tif w not in stop_words:\n","\t\tfiltered_sentence.append(w)\n","\n","print(word_tokens)\n","print(filtered_sentence)\n"],"metadata":{"id":"vlKsyIW1UZkn"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["filtered_words= ['one','two','three','four','five']\n","from nltk.stem.porter import PorterStemmer\n","porter = PorterStemmer()\n","stemmed = [porter.stem(word) for word in filtered_words]\n","print(stemmed)"],"metadata":{"id":"Xd_3nt9IZAY8"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from nltk.stem import PorterStemmer\n","from nltk.tokenize import sent_tokenize, word_tokenize\n","\n","ps = PorterStemmer()\n","example_words = [\"python\",\"pythoner\",\"pythoning\",\"pythoned\",\"pythonly\"]\n","for w in example_words:\n","    print(ps.stem(w))"],"metadata":{"id":"xwLaZnvIZA3X"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[""],"metadata":{"id":"zYK5ER0IbRMf"},"execution_count":null,"outputs":[]}]}